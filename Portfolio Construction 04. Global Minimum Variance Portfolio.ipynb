{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Construction 04: Global Minimum Variance Portfolio (GMV) and Equally Weighted Portfolio (EWP)\n",
    "\n",
    "## Unreliable Markovitz Portfolio Analysis\n",
    "\n",
    "Markovitz portfolio analysis of Efficient Frontier is highly sensitive to the estimated value of return.\n",
    "And the expected return is very difficult to estimate. \n",
    "\n",
    "Above all, in practice, Markovitz portfolio analysis of Efficient Frontier is <span style='color: blue;'> *__unreliable__* </span>. \n",
    "\n",
    "In other words, a small change in the return estimation can yield very different result about the asset allocation weight.\n",
    "\n",
    "It is called <span style='color: red;'> *__'Error Maximizing Nature of Markovitz'__* </span>. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways from the lecture\n",
    ">  1. Markowitz Analysis is extremely attractive in principle, because it allows you to build efficient portfolios.\n",
    ">  2. But in practice, its applicability is severely limited by the presence of errors in parameter estimates. \n",
    ">    *\ttypically, the asset that gets the largest allocation is typically not the asset that is the most attractive for the investor, as we wish it could be the case, but the asset that suffers from the largest amount of estimation risk\n",
    ">  3. In this context, it is very often the case that asset managers and investors are going to focus on portfolio construction methodologies that are not going to heavily rely on those parameter estimates.\n",
    "\n",
    "Estimation error is the key challenge in portfolio optimization, since optimizers tend to act as *__error maximizing machines__*.\n",
    "> * Expected return estimates are much harder to obtain with a good degree of accuracy compared to variance-covariance matrix estimates.\n",
    "> * It would require an advanced method for estimating covariance matrix parameter estimates. But what I'm seeing is for covariance matrix, we can eventually do a good job in getting reasonable parameter estimates. \n",
    "> *\tBut expected returns for a number of reasons, that's close to impossible. The sample-based expected return parameter estimates are very noisy, not very reliable.\n",
    "\n",
    "Nevertheless, on the efficient frontier, there is one single portfolio which does not change according to the return estimate.\n",
    "\n",
    "That is *__Global Minimum Variance Portfolio (GMV)__*.\n",
    "\n",
    "> “GMV is Maximum Sharpe Ratio Portfolio when the risk-free rate is not involved.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, we reproduce the Maximum Sharpe Ratio Portfolios on the efficient frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Games</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>Hlth</th>\n",
       "      <th>Chems</th>\n",
       "      <th>Txtls</th>\n",
       "      <th>...</th>\n",
       "      <th>Telcm</th>\n",
       "      <th>Servs</th>\n",
       "      <th>BusEq</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Trans</th>\n",
       "      <th>Whlsl</th>\n",
       "      <th>Rtail</th>\n",
       "      <th>Meals</th>\n",
       "      <th>Fin</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01</th>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>-0.0236</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>-0.0146</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-02</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>-0.0044</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0220</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-03</th>\n",
       "      <td>-0.0382</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>-0.0768</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0187</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>-0.0460</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-04</th>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>-0.0160</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>-0.0108</td>\n",
       "      <td>0.0269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05</th>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Food    Beer   Smoke   Games   Books   Hshld   Clths    Hlth  \\\n",
       "1996-01  0.0342  0.0326  0.0182  0.0469 -0.0049  0.0285 -0.0236  0.0595   \n",
       "1996-02  0.0162  0.0561  0.0318  0.0179  0.0233 -0.0044  0.0187 -0.0107   \n",
       "1996-03 -0.0382  0.0190 -0.0768  0.0108  0.0027  0.0130  0.1149  0.0024   \n",
       "1996-04 -0.0032 -0.0089 -0.0160  0.0237  0.0285  0.0388  0.0541 -0.0060   \n",
       "1996-05  0.0550  0.0969  0.0548  0.0279  0.0349  0.0325  0.0805  0.0393   \n",
       "\n",
       "          Chems   Txtls  ...   Telcm   Servs   BusEq   Paper   Trans   Whlsl  \\\n",
       "1996-01  0.0543 -0.0392  ...  0.0233  0.0143  0.0215  0.0121 -0.0012 -0.0065   \n",
       "1996-02  0.0276  0.0024  ... -0.0220  0.0423  0.0677 -0.0104  0.0418  0.0294   \n",
       "1996-03  0.0588  0.0268  ... -0.0187  0.0157 -0.0460  0.0306  0.0326  0.0243   \n",
       "1996-04 -0.0087  0.0346  ...  0.0270  0.0820  0.1056  0.0274  0.0265  0.0468   \n",
       "1996-05 -0.0037  0.0577  ...  0.0006  0.0352  0.0418  0.0144 -0.0028  0.0383   \n",
       "\n",
       "          Rtail   Meals     Fin   Other  \n",
       "1996-01 -0.0146  0.0657  0.0393  0.0283  \n",
       "1996-02  0.0553  0.0342  0.0213  0.0151  \n",
       "1996-03  0.0825  0.0083  0.0096  0.0500  \n",
       "1996-04  0.0436  0.0271 -0.0108  0.0269  \n",
       "1996-05  0.0511  0.0041  0.0141  0.0432  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "Folder=\"C:/Users/msugi/OneDrive/Desktop/DataScience/Courses/05. Investment Management & Machine Learning/01 Intro Portfolio Construction/Resources/data/\"\n",
    "filename4=\"ind30_m_vw_rets.csv\"\n",
    "Path4=Folder + filename4\n",
    "   \n",
    "ind = pd.read_csv(Path4, header=0, index_col=0)/100\n",
    "ind.index = pd.to_datetime(ind.index, format=\"%Y%m\").to_period('M')\n",
    "ind.columns = ind.columns.str.strip()\n",
    "ind_sub= ind[\"1996\":\"2000\"]\n",
    "ind_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annualize the return\n",
    "months=ind_sub.shape[0]\n",
    "ind_sub_anual=(((ind_sub + 1).prod())**(12/months)-1).round(4)\n",
    "#Calculate Covariance Matrix\n",
    "cov = ind_sub.cov()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring previousely defined functions here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(weights, returns):\n",
    "    return (weights.T @ returns)\n",
    "\n",
    "def portfolio_vol(weights, covmat):\n",
    "    return (weights.T @ covmat @ weights)**0.5\n",
    "\n",
    "def plot_efficient_frontier(n_points, ind_sub_anual, cov):\n",
    "    return_grid = np.linspace(ind_sub_anual.min(), ind_sub_anual.max(), n_points)\n",
    "    weights_frontier=[weight_minimize_vol(target_return, ind_sub_anual, cov) for target_return in return_grid]\n",
    "    returns_3=[portfolio_return(w, ind_sub_anual) for w in weights_frontier]\n",
    "    vol_3=[portfolio_vol(w, cov) for w in weights_frontier]\n",
    "    efficient_frontier_3 = pd.DataFrame({\"Return\": returns_3, \"Volatility\": vol_3})\n",
    "    \n",
    "    return efficient_frontier_3.plot.line(x=\"Volatility\", y=\"Return\", style=\".-\")\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def weight_minimize_vol(target_return, exptected_return, cov):\n",
    "\n",
    "#Generate 'weights' from a given 'target_returns'\n",
    "\n",
    "# number of assets\n",
    "    n = exptected_return.shape[0]\n",
    "    print(\"n=\", n)\n",
    "# Set the Initial Value: let's start from the equal weight\n",
    "    initial_weight=np.repeat(1/n, n)\n",
    "    print(\"initial_weight=\", initial_weight)\n",
    "# Set the contraints\n",
    "# 1) set the boundary: 0 < w < 1 for a sequence of bounds for every weight\n",
    "    condition_1_boundary = ((0,1),)*n\n",
    "    print(\"condition_1_boundary=\", condition_1_boundary)\n",
    " \n",
    "\n",
    "# Condition 2: check if the weights generates a portfolio that meets the target return\n",
    "\n",
    "    condition_2_return = {'type': 'eq',\n",
    "                          'args': (exptected_return,),\n",
    "                          'fun': lambda weights, exptected_return:  target_return - portfolio_return(weights, exptected_return)\n",
    "                         }\n",
    "\n",
    "# Condition 3: check if the weights sum to 1:\n",
    "\n",
    "    condition_3_weights_sum = {'type': 'eq',\n",
    "                          'fun': lambda weights:  np.sum(weights)-1\n",
    "                         }\n",
    "    output = minimize(portfolio_vol, initial_weight, args=(cov,), method=\"SLSQP\", \n",
    "                      constraints=(condition_2_return, condition_3_weights_sum), bounds = condition_1_boundary)\n",
    "    return output.x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to calculate *__Sharpe Ratio__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def Max_Sharpe_Ratio(risk_free_rate, expected_return, cov):\n",
    "\n",
    "#Generate 'weights' from a given 'target_returns'\n",
    "\n",
    "# number of assets\n",
    "    n = expected_return.shape[0]\n",
    "    print(\"n=\", n)\n",
    "# Set the Initial Value: let's start from the equal weight\n",
    "    initial_weight=np.repeat(1/n, n)\n",
    "    print(\"initial_weight=\", initial_weight)\n",
    "# Set the contraints\n",
    "# Condition 1) set the boundary: 0 < w < 1 for a sequence of bounds for every weight\n",
    "    condition_1_boundary = ((0,1),)*n\n",
    "    print(\"condition_1_boundary=\", condition_1_boundary)\n",
    " \n",
    "# Condition 2) check if the weights sum to 1:\n",
    "\n",
    "    condition_2_weights_sum = {'type': 'eq',\n",
    "                          'fun': lambda weights:  np.sum(weights)-1\n",
    "                         }\n",
    "    #Now in order to maximize Sharpe Ratio, I will minimize the negative of it!\n",
    "    def negative_Sharpe_Ratio(weights, risk_free_rate, expected_return, cov):\n",
    "        # calculate the negative of Sharpe Ratio\n",
    "        return4 = portfolio_return(weights, expected_return)\n",
    "        vol4 = portfolio_vol(weights, cov)\n",
    "        Negative_Sharpe_Ratio = - (return4 - risk_free_rate)/vol4\n",
    "        return Negative_Sharpe_Ratio\n",
    "    output = minimize(negative_Sharpe_Ratio, initial_weight, args=(risk_free_rate, expected_return, cov), method=\"SLSQP\", \n",
    "                      constraints=(condition_2_weights_sum), bounds = condition_1_boundary)\n",
    "    return output.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Sharpe Ratio Portfolio (Tangent Portfolio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "weight_MSRP:  [5.63675528e-16 4.00049000e-15 5.30227685e-15 4.52169955e-16\n",
      " 1.15825694e-15 0.00000000e+00 0.00000000e+00 4.55771646e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.45651200e-16 2.33844124e-01 0.00000000e+00 1.84959238e-15\n",
      " 0.00000000e+00 1.38733060e-01 1.73982387e-15 8.95567415e-02\n",
      " 0.00000000e+00 1.29454649e-15 1.56806265e-02 1.08571781e-15\n",
      " 0.00000000e+00 5.30623612e-16 6.64138017e-02 1.02566660e-15\n",
      " 2.09124014e-15 2.12765457e-15]\n",
      "# of weight_MSRP:  30\n",
      "0.2647174260564615 0.04572033899558562\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# set the risk free rate\n",
    "risk_free_rate = 0.1\n",
    "# weight of MSRP (Maximum Sharpe Ratio Portfolio)\n",
    "weight_MSRP = Max_Sharpe_Ratio(risk_free_rate, ind_sub_anual, cov)\n",
    "print(\"weight_MSRP: \", weight_MSRP)\n",
    "print(\"# of weight_MSRP: \", len(weight_MSRP))\n",
    "# Return of MSRP (Maximum Sharpe Ratio Portfolio)\n",
    "return_MSRP = portfolio_return(weight_MSRP,  ind_sub_anual)\n",
    "# Volatility of MSRP (Maximum Sharpe Ratio Portfolio)\n",
    "vol_MSRP = portfolio_vol(weight_MSRP,  cov)\n",
    "print(return_MSRP, vol_MSRP)\n",
    "# y range of Capital Market Line\n",
    "CML_y = [risk_free_rate, return_MSRP]\n",
    "# x range of Capital Market Line\n",
    "CML_x = [0, vol_MSRP]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Minimum Variance Portfolio\n",
    "\n",
    "Now, we will calculate *__the Global Minimum Variance Portfolio__*.\n",
    "\n",
    "> “GMV is Maximum Sharpe Ratio Portfolio when the risk-free rate is not involved.”\n",
    "\n",
    "In other words, in order to generate *__GMV__*, we need to create *__Maximum Sharpe Ratio Portfolio__* without the risk-free rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "vol_GMV= 0.0314 return_GMV= 0.1583\n"
     ]
    }
   ],
   "source": [
    "n= cov.shape[0]\n",
    "risk_free_rate_GMV=0\n",
    "expected_return_GMV=np.repeat(1, n)\n",
    "#Calculate the weights of GMV\n",
    "weight_GMV=Max_Sharpe_Ratio(risk_free_rate_GMV, expected_return_GMV, cov)\n",
    "# Calculate the return of GMV\n",
    "return_GMV = portfolio_return(weight_GMV, ind_sub_anual)\n",
    "# Calculate the variance of GMV\n",
    "vol_GMV = portfolio_vol(weight_GMV, cov)\n",
    "print(\"vol_GMV=\", vol_GMV.round(4), \"return_GMV=\", return_GMV.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot *__GMV__* on *__the Efficient Frontier__* together with *__Capital Market Line__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n",
      "n= 30\n",
      "initial_weight= [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      " 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333]\n",
      "condition_1_boundary= ((0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae38ad4cc8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9b3/8dcnk5UkZGVNICEsAspmIoL7RhHxgrbuaF1/VCu32tZ71Wtrq23vdalV29LrVrW1KsWlvdZiRajWFSGssoiEJSbsgSQQQtb5/v6YIYYYYLJOZvJ+Ph48mJlz5pxPtvec8z3f8/2acw4REQlfEcEuQEREOpaCXkQkzCnoRUTCnIJeRCTMKehFRMJcZLB2nJ6e7rKzs4O1exGRkLR06dIS51yvlrwnaEGfnZ1Nfn5+sHYvIhKSzKywpe9R042ISJhT0IuIhDkFvYhImAtaG31zamtrKS4upqqqKtildBmxsbFkZmYSFRUV7FJEJER1qaAvLi4mMTGR7OxszCzY5QSdc449e/ZQXFzMoEGDgl2OiISoLtV0U1VVRVpamkLez8xIS0vTGY6ItEmXCnpAId+Evh8i4WlpYSmz3y1gaWFph++rSzXdiIiEO+cc76zdya0vLaOu3hEdGcFL/28CuVkpHbZPBX0THo+HUaNGUVdXx6BBg3jhhRdITk4+4vplZWW89NJLfPe73+3EKkUkVJQfrOWz4nJWFpexoqiMlUVl7Npf3bC8tt7Lok17FPSdKS4ujhUrVgBw7bXXMnv2bO65554jrl9WVsbvfve7Fgd9fX09Ho+nTbWKSNdSXVfPuu37WekP9BXFZWzafaBheU56PKcOSSe1RxQvfPol9fVeoiIjmJCT1qF1hXzQLy0sZdGmPUzISWv3T8SJEyeyatWqhucPP/wwc+fOpbq6mosvvpj77ruPu+66i40bNzJ27FgmTZrE1KlT+eUvf8mbb74JwKxZs8jLy+O6664jOzubG264gfnz5zNr1iyeeOIJTj75ZN59913Kysr4/e9/z+mnn96uX4OIdAyv17GppIIVReW+YC8uY932fdTW+2bt65UYw9gByXzrxEzGZCYzKjOJpLivuklfMLp/h2VXUwEFvZmdDzwOeIBnnHMPHGG9S4BXgJOcc20ayOa+v61h7bZ9R11nf1Utn+/Yj9dBhMHwvokkxh65v/nI/j35yb8dH9D+6+vrWbhwITfeeCMA8+fPZ8OGDSxevBjnHNOmTeP999/ngQceYPXq1Q1nAe+9995RtxsbG8uHH34IwBNPPEFdXR2LFy9m3rx53HfffSxYsCCg+kSkc+0or/I1vRT7jtY/Ky5nf3UdAAkxkYzKSOLG03IYOyCJMQOS6dsz9qidKXKzUjo84A85ZtCbmQeYDUwCioElZvaGc25tk/USge8Bn3ZEoc3ZV1WH1z/lrdf5nh8t6ANx8OBBxo4dy5YtW8jNzWXSpEmAL+jnz5/PuHHjAKioqGDDhg0MHDiwRdu//PLLD3v+zW9+E4Dc3Fy2bNnSptpFpH00blc/dLS+c5+vXT3KY4zo15Pp4/ozJjOZsQOSyemVgCei6/aQC+SIfjxQ4JzbBGBmc4DpwNom6/0MeAi4oz0KC+TIe2lhKTOeWURtna+d6/ErxrX5E/JQG315eTkXXnghs2fP5nvf+x7OOe6++26+853vHLZ+03COjIzE6/U2PG/aBz4+Pv6w5zExMYDvInBdXV2baheRlgukXf2UwemMyfQdqY/o15PYqNC6vhZI0GcARY2eFwMnN17BzMYBA5xzb5rZEYPezGYCM4EWHwk3JzcrhRdvmtAh7VxJSUn8+te/Zvr06dxyyy1MnjyZH//4x8yYMYOEhAS2bt1KVFQUiYmJ7N+/v+F9WVlZrF27lurqaqqqqli4cCGnnXZau9UlIq3na1c/0HCUvrKojLWN2tXTE3zt6t8cl8GYAcmMzkgmqUfoDz8SSNA3dz7iGhaaRQCPAtcda0POuaeApwDy8vLcMVYPSEe2c40bN44xY8YwZ84crrnmGtatW8fEiRMBSEhI4E9/+hODBw/m1FNP5YQTTmDKlCk8/PDDXHbZZYwePZqhQ4c2NPWISOdr3K6+qriMVUVftavHR3sYnZnMjaflNByt90s6ert6qDLnjp63ZjYR+KlzbrL/+d0Azrn/8T9PAjYCFf639AX2AtOOdkE2Ly/PNZ14ZN26dYwYMaJ1X0kY0/dF5Nj2Vfna1Q/1VW/crh4Z4WtXHzMgKWTa1Y/EzJY65/Ja8p5AjuiXAEPNbBCwFbgCuOrQQudcOZDeqIj3gDva2utGRORIPt20hzdXbScmKoK9B2pYWVTGxkbt6oPS45mYk8aYAcmMGZDMyBBsV29Pxwx651ydmc0C3sbXvfJZ59waM7sfyHfOvdHRRYpI97b3QA3LCkvJLyzlX+t3sW7HV9fFkuKiOCk7lYvDrF29PQXUj945Nw+Y1+S1e4+w7lltKcg5F5ZtZK11rKY1kXDjnGPj7gP+YN9LfmFpQy+YKI+RnhCD4btQGGEw84xB3Hr20KDW3NV1qTtjY2Nj2bNnj4Yq9js0Hn1sbGywSxHpMFW19awqLmdpYSlLC/eytLCU0spaAJJ7RJE7MIVLcjPJy0pldGYSa7btO6xb9YSc9GPsQbpU0GdmZlJcXMzu3buDXUqXcWiGKZFwsXt/dUOo5xeWsnpreUP3xpz0eM4b0Ye87BRys1LJSY8noskF047sVh2uulTQR0VFaSYlkTDi9To27Kpgqb8ZZmlhKYV7KgGIjoxgdEYSN5w2iLysVHKzUkiNjw5ou505fEA46FJBLyKhrbKmjpVF5Q1H68sKS9lX5eu3nhYfTW5WCjNOHkhuVionZPQkJrL79oTpTAp6EWm1HeVVhx2tr922jzr/AFRDeycwdXQ/crNSyctKISuth669BYmCXkQCUu91fL5jX0M3x/wtpWwtOwhAbFQEYzKT+c6ZOeRlpTJuYDLJPQJrhpGOp6AXkWZVVNex/MtS/4XTUpZ/WUaFf/iA3okx5GWn+NvXUxjZvydRni43BbX4KehFujnf5D0lDO6VQHWd19cUs6WUz3fsw+vADI7rk8hF4/o3XDTNTIlTM0wIUdCLdFPFpZW8uKiQJ9/f1DCvA0CPaA/jBiYz65yh5GWlMHZgMj3bOM+DBJeCXqSbKK+s5ZNNJXywoYSPCkrY4u/meIgB10zM4t4LRxKpZpiwoqAXCVPVdfUsLSzlo4ISPtxQwmdby/E63/C8E3LSuPaUbFJ7RHPn66sa7jKdPjZDIR+GFPQiYcLrdXy+Yz8fFuzmw4I9LN68h6paL54IY9yAZP79nKGcPjSdMQOSD7twmpnaQ3eZhjkFvUgI21p2kI82lPBBQQkfF5Sw50ANAEN6J3DFSQM5bUg6J+ekHnUuZd1lGv4U9CIhpPxgLZ9s3MNHBb529k0lvlEdeyXGcMawXpw2JJ1Th6TTN0kD4clXFPQiXVh1XT3Lvyzjww0lfFhQwqriMrzO1zNmQk4aMyZkcfrQdIb2TlB3RzkiBb1IF+Kcr539owJfsH+6aS8Ha+vxRBhjMpOYdc5QThuSztgByURH6qKpBEZBLxJk28sPNnR5/KighJIKXzv74F7xXJaXyWlDe3FyTqr6skurKehFOoHv7lNfz5ahfRJY5G9n/6CgpGH2pPSEmIY29tOGptMvKS7IVUu4UNCLdLAlW/Yy4+lPqa33gvluTPI6iIvycHJOKleNH8hpQ9M5rk+i2tmlQyjoRTrAgeo6Ptiwm/lrdzLvs+3U1Ht9CxxMyEnl9vOGMW5gitrZpVMo6EXayfbygyxct4sF63byccEeauq9JMVFMX5QKp9s3IPX64iKjOCOycPVb106lYJepJWcc6zdvo8Fa33h/tnWcgCy0nrw7YlZnDeyD3lZKUR6Ig5ro1fIS2dT0Iu0QHVdPYs27WXhup0sWLuTbeVVmMGJA1O48/zhTBrZm8G9vt6nXXefSjAp6EWOofRADe+u9x21/2v9bg7U1BMX5eH0oencPmkY5wzvTXpCTLDLFDkiBb1IMzaXHGDhup3MX7uT/C178TrfrErTxmYwaWRvThmcTmyUJraW0KCgF8E3H+qKolLe8be3F+yqAGB430RuPXsI543ow6iMJCIi1P1RQo+CXrqtypo6PthQwoK1O/nn57vYc6CGyAhjQk4aV588kHNH9GFAao9glynSZgp66VZ27qtiwbqdLFy3iw8LSqip89IzNpKzh/fmvBF9OPO4XhpqQMKOgl7C2tIte3lj5Xaq6+pZu30fq4p9XSAHpMZx9clZnDeyNydlpx42EYdIuFHQS1gq2lvJb/65gVfyizk07/WwPgn8x+TjmDSyj4b1lW5FQS9ho6q2nrfX7GBufhEfFew5bJnHYPrYDG49e0iQqhMJHgW9hDTnHKuKy5mbX8QbK7exv6qOAalx/GDSMI7rm8htc5Y3THw9ISct2OWKBIWCXkLSnopq/rJ8K6/kF7N+535iIiO4YFQ/Ls3LZMKgtIZukC/eNEFDD0i3F1DQm9n5wOOAB3jGOfdAk+U3A7cC9UAFMNM5t7ada5Vurq7ey/sbdjN3STEL1u2kzusYOyCZ/754FBeO6ddsbxkNPSASQNCbmQeYDUwCioElZvZGkyB/yTn3hH/9acCvgPM7oF7phjburuCV/GJeX1bMrv3VpMVHc/2p2VyaN4BhfRKDXZ5IlxfIEf14oMA5twnAzOYA04GGoHfO7Wu0fjw0dHQQaZWK6jrmrdrO3Pwi8gtL8UQYZx/Xi0vzBnDO8N7qDinSAoEEfQZQ1Oh5MXBy05XM7FbgB0A0cE67VCfdinOO/MJS5i4p4u+fbaeypp6cXvHcNWU43xyXQe+escEuUSQkBRL0zXU2/toRu3NuNjDbzK4CfgRc+7UNmc0EZgIMHDiwZZVK2Nq5r4rXlhXzSn4xm0sOEB/tYdqY/lyaN4ATByarv7tIGwUS9MXAgEbPM4FtR1l/DvC/zS1wzj0FPAWQl5en5p1u6NAEHHlZKew9UMPc/CL+9cVuvA7GD0rl1rOHcMGovvSIVocwkfYSyF/TEmComQ0CtgJXAFc1XsHMhjrnNvifTgU2INLE0sJSrnp6ETV13oZTwr49Y7nlrMFckjuAQenxQa1PJFwdM+idc3VmNgt4G1/3ymedc2vM7H4g3zn3BjDLzM4DaoFSmmm2ke6tqraexxZ8QXWdt+G1S3IzePBbY/Bo6F+RDhXQ+bFzbh4wr8lr9zZ6fFs71yVhwjnHP1bv4Bfz1lFcepBDmR4dGcGV47MU8iKdQA2h0mHWbtvHfX9bw6eb9zK8byIv3XQyMVEe3akq0skU9NLu9lRU88g7XzBn8ZckxUXxs4tO4MqTBhDp7/uugBfpXAp6aTc1dV7++MkWHl+4gYM19Vx7Sja3nzuMpB6ayEMkmBT00i7eXb+Ln725lk27D3DGsF7ce+EIhvTW8AQiXYGCXtqkYFcFP//7Wt5bv5uc9HievS6Ps4/rrZucRLoQBb20SvnBWh5fsIE/frKFuCgPP5o6gm9PzCY6UmPQiHQ1CnppkXqvY86SL3lk/heUVtZwxUkD+OE3jiM9ISbYpYnIESjo5Zi279/O1BcvYWLy/az+MoLCvZWMH5TKvReO5ISMpGCXJyLHoKCXY7r5jbtZvuMTNmx9hPTaW7njG8O49ewhaocXCREKejmiuF/EUVVX5XtiUBH5FhWRb/H9j2KYdU5VcIsTkYDpypk0q7KmlttG/oMedWdw6NfEXAyJ3rN485IVwS1ORFpEQS9f89D7v6fPgyN46dMShvfpQ4RBtCcGrIbJI3KYPGJ4sEsUkRZQ0EuDunovs98t4Nfz9+BxqTx25XFk9arj5tybWXzTp9ySdwv1VhrsMkWkhcy54Mz/kZeX5/Lz84Oybzmc13m54x/3smDNPvaVTObC0f34+UUnkNwjOtiliUgTZrbUOZfXkvfoYmw355zjpU+LeHrRu0RZAs9feRfTxvQPdlki0o4U9N3UgZoD3PXOT9ix7VyWbPTyb0Me5FeX5tE3SRNwi4QbBX039cKSZczO/y196ut5aPptXD0hS/3iRcKUgr4bWbh+I7/Pf42Ig2fyYcE+vpHxZ/73yvM0V6tImFPQdxNLC0u59MX/ojTidTKqn+bb40/k/uknNEwGIiLhS0Ef5or3FVNVV8UfP95PQs2lxNrpRNOLjJQeCnmRbkJBH8bqvfWc+fyZxNCHym334LE4ohhEVGQEE3LSgl2eiHQSBX0YKiovIrNnJkYEZ/b6L95e5Zg6sg/Xn5rNsi/LNDG3SDejoA8zS7Yu4fTnTufpf3uWxWtH8M+VfblxYhY/+bfj8UQYEwenB7tEEelkCvowUVVXRWxkLCf2O5FbT7qN1z5OYkXhNu48fzg3n5mjrpMi3ZiuxoWBxxY9xuj/Hc2BmgPs2l/D6rVTWVNsPHr5GG45a7BCXqSb0xF9CHPOYWbk9svlrOyz+HxHObNeXMf+qjqev348pw5RM42IKOhDUm19Lbf8/RaGpg7lztPu5PSs04msG8l1z+bTI9rD3O9MZGT/nsEuU0S6CAV9CIryRLG/Zj+VtZUsLSzluY8284/VO8hOj+cPN4wnIzku2CWKSBeiNvoQsaNiB9f+9Vq2798OwJxvzWFazu1c/uQnvLlqO17nuHfqSIW8iHyNgj5E7Kvexxvr32Dx1sUAmBl/+mQLdV7ffAIGfLatPHgFikiXpaDvwgr2FvDbxb8FYFjaML68/UumD58OwIHqOj7YUIIBHkN3u4rIEamNvgt7Mv9Jnln+DFeccAXpPdJJjElsWPbYgi8oOVDDf198AqWVtbrbVUSOSEHfxazYsYIYTwwjeo3gp2f9lNsn3E56j8O7Sa7dto9nP9rCleMHcNXJWUGqVERChZpuupDqumqmvDiFOxfcCUB8dDwZPTMOW8frddzz189IjovizvOHB6NMEQkxAQW9mZ1vZuvNrMDM7mpm+Q/MbK2ZrTKzhWamw8wWWLljJc45YiJjeO2y13j+ouePuO7LS75k+Zdl3DN1hCbvFpGAHDPozcwDzAamACOBK81sZJPVlgN5zrnRwKvAQ+1daLhauGkhY58cy6trXwXglAGnkBqX2uy6u/dX8+BbnzMxJ42Lx2U0u46ISFOBHNGPBwqcc5ucczXAHGB64xWcc+865yr9TxcBme1bZvjZU7kHgLOyz+JX3/gVFwy94Jjv+fnf11JV6+XnF5+g8WtEJGCBBH0GUNToebH/tSO5EXiruQVmNtPM8s0sf/fu3YFXGWbufOdOTnr6JA7UHMAT4eH7E79PfPTR5239cEMJ/7diGzefNZjBvRI6qVIRCQeB9Lpp7tDRNbui2dVAHnBmc8udc08BTwHk5eU1u41w5ZzD67x4IjxcOOxCEmMSifJEBfTeTzaW8O8vL6Nvzxi+e9bgDq5URMJNIEf0xcCARs8zgW1NVzKz84B7gGnOuer2KS88HKw9yOQ/Teahj3yXLk7POp0fnfEjoj3Hvpi6tLCUa36/mNLKWvYeqGXNtn0dXa6IhJlAgn4JMNTMBplZNHAF8EbjFcxsHPAkvpDf1f5lhra4qDgye2aS1qPld64u2rSnYZiDeq+XRZv2tHd5IhLmjhn0zrk6YBbwNrAOmOucW2Nm95vZNP9qDwMJwCtmtsLM3jjC5rqNz0s+Z/KfJjcMQvbs9GeZmTuzxduZkJPW0HamYQ5EpDUCujPWOTcPmNfktXsbPT6vnesKeREWwbrd69iwdwP9Evu1ejvD+ybigNOHpHP7pGEa5kBEWkx3xrajj4s+5n8++B/ANwjZxu9t5IysM9q0zY27KwCYMSFLIS8iraKgb0evrX2NJ5c+yf7q/QAB96o5mg07fUE/pLe6VIpI6yjo22jehnms3rUagJ+d8zM+u+Wzw0aZbKsNuyqI8hhZaT3abZsi0r0o6NugoqaC6/56HQ9+9CAAPaJ6tGvIAxTs2s+g9HiiPPpRiUjraJjiFnLOsXDzQs4ddC4J0Qks/PZChqUN67D9Feyq4Pj+SR22fREJfzpMbKG/fv5XJr0wib9v+DsAo/qMIiYypkP29cnGEgr3VBIf4+mQ7YtI96CgD0C9t57CskIAph03jRe/+SJThkzpsP1t3AiXXlPFqSOT2PLgBfxyxkguvaaKjRs7bJciEsYU9AG48Y0bOfP5M6msrcQT4eGqUVfhieiYo+y33oLRo+H1l2NwNVGA4WqieP3lGEaP9i0XEWkJtdEfQU19DYYR5YliZu5Mzss5j7jIuA7d58aNcMklUFkJTceS89YblZW+5atWwWCNbSYiAdIRfTPKq8rJfSqXhz9+GPBNBnL16Ks7fAz4Rx6B2tqjr1NbC48+2qFliEiYUdA34pxv8LCk2CTOHXQuY/uO7dT9/+lPgQX9Cy90Tj0iEh4U9H6Lihdx4lMnsm2/bwTmx85/LKBZn9pTRUX7riciAgr6BmlxaRhGSWVJ0GpICHCUg0DXExGBbh70r6x5hXsW3gPA0LShLJ25lNF9RgetnquvhqhjDI8TFQXXXNM59YhIeOjWQf/p1k9ZsHkBVXVVAEGfcPuHPwws6L///c6pR0TCQ7cKeq/z8kT+E6zauQqAX5zzCz6+4WNiI2ODXJnP4MHw6qvQo8fXAz8qyvf6q6+qa6WItEy3CvryqnLuffdenlv+HAAxkTEdduNTa02Z4usnP3MmxCd4AUd0XD0XXVHFqlW+5SIiLRH2N0zV1tfyytpXuPKEK0mJS2Hx/1tMVlJWsMs6qsGD4be/hdOvLebO1z7DgFVREZRFTgA0+YiItEzYH9G/vPplZrw+g38V/guA7OTsoLfFB2rj7gMAOKC2ThODi0jrhGXQV9ZWsnb3WgBmjJrBwm8v5Kzss4JbVCucfVwvwDcYgiYGF5HWCsugv+yVy5j60lRq6mvwRHg4Z9A5wS6pVSYOTicxxsPozCRevGmC5owVkVYJmzb60oOlJEQnEOWJ4t4z7+Vg7UGiPdHBLqvNMlJ60CsxRiEvIq0WFkf0Oyt2MmL2CB766CEAxmeM58zsM4NcVfvo0zOWnfuqg12GiISwkA762nrfCGB9EvowM3dmp49N0xn69oxlx76qYJchIiEsZIN+3oZ5DPnNELbu2wrA/Wffz7h+44JcVfvrkxRLSUU1tfXeYJciIiEqZIN+WNowju91PLXeY4zrG+L69IzBOSipUPONiLROSAX9Ix8/wm1v3QbAkNQhzJsxj+zk7OAW1cH69vQNzzD7nwUsLSwNcjUiEopCKuh3VOygaF8Rdd66YJfSafYeqAHgxU+/ZMYzixT2ItJiXTroD9Ye5O4Fd7Nyx0oAHjjvAV6//HUiI8KmV+gxFZdWAro7VkRar2sHfd1BnlvxHG8VvAXQ5QYg6wxnDOvdME247o4VkdbockFfVlXG44sexzlHalwqa767hrtOuyvYZQVNblYKU0b1JTLC+MP143XjlIi0WJcL+rlr5vKD+T9g2fZlAKT10BHshaP7U+d1REV2uR+XiISALpEcOyt2kr8tH4CbTryJFd9ZQW7/3CBX1XWclJ0KwJLNe4NciYiEooCC3szON7P1ZlZgZl9rRzGzM8xsmZnVmdklgWxz/Z717KjYAcC35n6Lq167inpvPREWwag+o1r0RYS7Xokx5KTHs1hBLyKtcMygNzMPMBuYAowErjSzkU1W+xK4Dngp0B1XVFfwk/d+AsBvpvyGN658o1tebA3U+EGpLNmyF6/XBbsUEQkxgRzRjwcKnHObnHM1wBxgeuMVnHNbnHOrgBbdp//U0qew+4xTnj2F4enDW/LWbuek7FT2VdWxfuf+YJciIiEmkKDPAIoaPS/2v9ZiZjbTzPLNLB8gNjKWGaNmsPm2za3ZXLcyfpCvnf6X89frpikRaZFAgr65efda1X7gnHvKOZfnnMszM2rqa+gZ05O+CX1bs7luZZd/BMuF63bpDlkRaZFAgr4YGNDoeSawra07HpE+gptzb264ICtHt6jRhVjdISsiLRHIWAJLgKFmNgjYClwBXNXWHcdFxTF76uy2bqbbmJCTRpTHqK13RESY7pAVkYAd84jeOVcHzALeBtYBc51za8zsfjObBmBmJ5lZMXAp8KSZrenIoruj3KwUXrzpZOKjPYzJTNYdsiISsIBGB3POzQPmNXnt3kaPl+Br0pEONH5QGtdMzObpDzaxa18Vvf1DGIuIHE2XuDNWAndpXib1Xsfry7cGuxQRCREK+hAzuFcCeVkpzM0vwjndPCUix6agD0GX5Q1g0+4DLPtSXSxF5NgU9CHogtH96BHt4ZX84mCXIiIhQEEfghJiIpk6qh9/W7mNypruM62iiLSOgj5EXXbSAA7U1PPDuSt1l6yIHJWCPkRF4Bub4q3VOzQkgogclYI+RDUeEqFGQyKIyFEo6EPUhJw0YqJ8Pz7n4KRs3SkrIs1T0Ico35AIE7hobH8csHH3gWCXJCJdVEBDIEjXlJuVwokDkykuPcgj879g2pj+xMfoRyoih9MRfYgzM/5r6ghKKqp56v1NwS5HRLogBX0YOHFgClNH9eOp9zex0z9BiYjIIQr6MPGf5x9HndfLo+98EexSRKSLUdCHiay0eK6ZkM3c/CLW79AE4iLyFQV9GPn3c4YQHxPJXa+vYva7BbqJSkQA9boJKynx0Vw8LoM/flLIyqIyoiMjePGmCZqNSqSb0xF9mEmLjwbA6zSJuIj4KOjDzGlDexHtOfRj1STiIqKgDzu5WSm8PHMCpwxOo945iksrg12SiASZgj4M5Wal8McbxpOblcKP/rKaor0Ke5HuTEEfpiI9ETx2+VgAbpuznLp6b5ArEpFgUdCHsQGpPfj5xSew7MsyfvPPgmCXIyJBoqAPc9PHZvDNEzP4zT83sGTL3mO/QUTCjoK+G7h/+glkpvTg9jkrKD9YG+xyRKSTKei7gYSYSB6/Yiw79lXxo7+uxjkX7JJEpBMp6LuJcQNT+MGkYfxt5TZufXGZhkcQ6UYU9N3I+EGpRBjMW72Dq57WhOIi3YWCvhtZ3GhC8eo6LwvW7QxiNSLSWRT03ciEnDSiI7KDMz0AAA0kSURBVCOIMN/zf6zezoHquuAWJSIdTkHfjRyaUPyH3ziOey4YQeGeSr738nLqvbo4KxLONExxN5ObldIwbHFsVAQ//r81/OzNtfx02vFBrkxEOoqCvhu7ZmI2hXsqeebDzWSl9eD6UwcFuyQR6QABNd2Y2flmtt7MCszsrmaWx5jZn/3LPzWz7PYuVDrG3ReMYPLxfbj/zbW8s1YXZ0XC0TGD3sw8wGxgCjASuNLMRjZZ7Uag1Dk3BHgUeLC9C5WO4YkwHrt8HKMzkvjey8v5rLg82CWJSDsL5Ih+PFDgnNvknKsB5gDTm6wzHfiD//GrwLlmZu1XpnSkuGgPT1+bR2p8NDf8YQlbyw4GuyQRaUeBBH0GUNToebH/tWbXcc7VAeXA16Y2MrOZZpZvZvm7d+9uXcXSIXonxvLc9SdRVVvPVU8t4tF31uuGKpEwEUjQN3dk3rQ/XiDr4Jx7yjmX55zL69WrVyD1SSca1ieRH5w3jMK9lTy+sIAZz+juWZFwEEjQFwMDGj3PBLYdaR0ziwSSAI2JG4Iqa+sbPrWrar18vLEkqPWISNsFEvRLgKFmNsjMooErgDearPMGcK3/8SXAP52GSAxJE3LSiImKaAj7jwtKNDuVSIg7ZtD729xnAW8D64C5zrk1Zna/mU3zr/Z7IM3MCoAfAF/rgimh4dDds3dMPo7rTsnik017+f7clQp7kRAW0A1Tzrl5wLwmr93b6HEVcGn7libB0vju2b5JcTzw1udERRgPXzoGT4Q6U4mEGt0ZK0d185mDqav38sv5X+CJMB781mgiFPYiIUVBL8c065yh1NY7Hl+4gUhPBL+46ASFvUgIUdBLQG4/byi19V5+995GojzGfdOOR/fEiYQGBb0ExMz4j8nHUed1PPX+JiIjIvjxhSMU9iIhQEEvATMz7p4ynNp6L89+tJkoj3HXlOEKe5EuTkEvLWJm3HvhSGrrvTz5/iaWF5Vy/SmDOG9kH6I8msdGpCtS0EuLmRkXjc3g5U+LWLy5lMWbSzGgb1Is/ZPj/P9iyUiOo39SHBkpvtd6xkbq6F8kCBT00iqfbt6L8w9nZMCEnFT6J/dgW9lBVhWX8fbqKmqa3GSVEBNJ/+SvPgwy/P8OfTD06RmrswKRDqCgl1Y5NNF4bZ2XqMgI7pg8vOEmKwCv11FSUc3WsoNsK6tiW9lB/2Pf/yuLyiitrD1smxEGfXrGNgr/ODKSG58lxJEUF9XZX6pIyLNgDUmTl5fn8vPzg7JvaR9LC0tZtGkPE3LSDgv5QFXW1DV8CBz6ADj0YbCtrIrt5QeprT/89zMxJrLhDOCwMwN/81CfxBgidVYgYczMljrn8lryHh3RS6s1HiqhNXpERzKkdwJDeic0u/zQWUFxQ/j7PgAOfRisOMJZQd+ejT4EUr5+ZtAzVmcF0r0o6KXLiogweveMpXfPWE4c2PwHyoHqOraXH2Rr0zOD0oMsLypl3mfbqfM2f1bg+xCIbTgrOPRBoLMCCTcKeglp8TGRDOmdyJDeic0urz/sWoHvA8D3YeD7YFj2ZSllTc4KPBHmPys4/PpAZqMLx4k6K5AQoqCXsOaJMPr09PXoOdpZwVcXiw8/M1haWMrfVzVzVhAb2XAW0Ljn0KHHvXVWIF2Igl66vfiYSIb2SWRonyOfFezeX93oQnHjHkRVLC0spfxg82cFGUe5cJwQoz8/6Rz6TRM5Bk+E0Tcplr5JsUe8+FxRXcf2soPNXjjOLyxlRzNnBT1jI792fSAj5asLx70TY1lRVNamnk0ioKAXaRcJAZwV7Npfddj1gUP/iksPsmTLXvZV1R32Ho/Boc+GmKgIXrxpgsJeWkVBL9IJPBFGv6Q4+iXFkZvV/Dr7q2rZXv5V99E3Vmzj0817Aait87Jo0x4FvbSKgl6ki0iMjSIxNoph/rOC4X17MuOZRQ13H0/ISQtyhRKqFPQiXdShidrVRi9tpaAX6cLaevexCIA6+oqIhDkFvYhImFPQi4iEOQW9iEiYU9CLiIQ5Bb2ISJgL2gxTZrYfWB+UnbddOlAS7CLaIJTrV+3BodqDp2n9Wc65Xi3ZQDD70a9v6XRYXYWZ5Ydq7RDa9av24FDtwdMe9avpRkQkzCnoRUTCXDCD/qkg7rutQrl2CO36VXtwqPbgaXP9QbsYKyIinUNNNyIiYU5BLyIS5jok6M3sfDNbb2YFZnZXM8tjzOzP/uWfmll2o2V3+19fb2aTO6K+o2lt7WY2ycyWmtln/v/PCZXaGy0faGYVZnZHZ9XcaN9t+Z0ZbWafmNka//c/tjNr99fQ2t+bKDP7g7/udWZ2dxes/QwzW2ZmdWZ2SZNl15rZBv+/azuv6ob9t6p2Mxvb6HdmlZld3rmVt+377l/e08y2mtlvj7kz51y7/gM8wEYgB4gGVgIjm6zzXeAJ/+MrgD/7H4/0rx8DDPJvx9PeNXZQ7eOA/v7HJwBbO6vuttbeaPlrwCvAHaFSO757QVYBY/zP0zrzd6Yd6r8KmON/3APYAmR3sdqzgdHAH4FLGr2eCmzy/5/if5wSIrUPA4b6H/cHtgPJoVB7o+WPAy8Bvz3W/jriiH48UOCc2+ScqwHmANObrDMd+IP/8avAuWZm/tfnOOeqnXObgQL/9jpLq2t3zi13zm3zv74GiDWzmE6p2qct33fM7CJ8f6hrOqnextpS+zeAVc65lQDOuT3OufpOqvuQttTvgHgziwTigBpgX+eUDQRQu3Nui3NuFeBt8t7JwDvOub3OuVLgHeD8zijar9W1O+e+cM5t8D/eBuwCWnS3aRu15fuOmeUCfYD5geysI4I+Ayhq9LzY/1qz6zjn6oByfEdigby3I7Wl9sa+BSx3zlV3UJ3NaXXtZhYP3Anc1wl1Nqct3/dhgDOzt/2nuf/ZCfU21Zb6XwUO4Dui/BL4pXNub0cX3Fxdfi35mwuFv9djMrPx+I6qN7ZTXYFode1mFgE8AvxHoDvriCEQrJnXmvbhPNI6gby3I7Wldt9Cs+OBB/EdaXamttR+H/Coc67Cf4Df2dpSeyRwGnASUAksNLOlzrmF7VviUbWl/vFAPb7mgxTgAzNb4Jzb1L4lHlFb/uZC4e/16Bsw6we8AFzrnPvakXMHakvt3wXmOeeKAv177Ygj+mJgQKPnmcC2I63jP2VNAvYG+N6O1JbaMbNM4C/At51znXl0cFhdfi2p/WTgITPbAtwO/JeZzerogpury6+lvzP/cs6VOOcqgXnAiR1e8RFq82tJ/VcB/3DO1TrndgEfAZ05Lktb/uZC4e/1iMysJ/B34EfOuUXtXNuxtKX2icAs/9/rL4Fvm9kDR31HB1xkiMTX1juIry4yHN9knVs5/MLUXP/j4zn8YuwmOvdibFtqT/av/63Oqre9am+yzk/p/Iuxbfm+pwDL8F3IjAQWAFNDqP47gefwHeHFA2uB0V2p9kbrPs/XL8Zu9v8MUvyPU0Ok9mhgIXB7Z/6utEftTZZdRwAXYzvqi7gA+AJfm9c9/tfuB6b5H8fi691RACwGchq99x7/+9YDU4LwA2hV7cCP8LW1rmj0r3co1N5kGz+lk4O+HX5nrsZ3EXk18FBn197G35sE/+tr8IX8f3TB2k/CdwR6ANgDrGn03hv8X1MBcH2o1O7/nalt8vc6NhRqb7KN6wgg6DUEgohImNOdsSIiYU5BLyIS5hT0IiJhTkEvIhLmFPQiImFOQS8hy8zesyYjnJrZ7Wb2uyOsn21mq4+xzWwzu6rR8zwz+7X/8XWHRgo0s5vN7NuNXu/f1q9HpKMo6CWUvYzv5qPGrvC/3lrZ+O5WBcA5l++c+17TlZxzTzjn/uh/eh2+IQxEuiQFvYSyV4ELD40S6h/jvT/woZk9bGar/eO8f22scf+R+wf+gdCWmdkp/kUPAKeb2Qoz+76ZnWVmbzbz/p+a2R3+ccLzgBf975lqZn9ptN4kM3u93b9ykRZQ0EvIcs7twXeX6aGhca8A/gx8ExgLjAHOAx72D17V2C5gknPuROBy4Nf+1+8CPnDOjXXOPRpADa8C+cAM59xYfGPtjDCzQ0PeXo9viAORoFHQS6hr3HxzqNnmNOBl51y9c24n8C98t5M3FgU8bWaf4RuCYGR7FON8t5q/AFxtZsn4BqB6qz22LdJaHTFMsUhn+ivwKzM7EYhzzi07dJH0GL4P7MR31B8BVLVjTc8Bf/Nv8xXnG39eJGh0RC8hzTlXAbwHPMtXF2HfBy43M4+/CeUMfE08jSUB251vDPJr8E3tBrAfSGxhGYe9x/lmLNqGb6C751u4LZF2p6CXcPAyviPzOf7nf8E3j+xK4J/AfzrndjR5z++Aa81sEb5Zqg74X18F1JnZSjP7foD7fx54wn8xNs7/2otAkXNubWu+IJH2pNErRTqAv7/9cufc74Ndi4iCXqSdmdlSfGcIk1znzhss0iwFvYhImFMbvYhImFPQi4iEOQW9iEiYU9CLiIQ5Bb2ISJj7/2Xjhs956sU7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Draw the Efficient Frontier\n",
    "ax = plot_efficient_frontier(20, ind_sub_anual, cov)\n",
    "ax.set_xlim(left=0)\n",
    "# Draw the CML\n",
    "ax.plot(CML_x, CML_y, color=\"green\", marker='*', linestyle=\"dotted\")\n",
    "# Plot GMV\n",
    "ax.plot([vol_GMV], [return_GMV], color=\"blue\", marker=\"o\", markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
